{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from models import filter_terms_not_in_wemodel, \\\n",
    "    get_2ndorder_association_metric_list_for_target_list, \\\n",
    "    get_1storder_association_metric_list_for_target_list, \\\n",
    "    save_array, open_pickle, save_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_model_name = \"sg_dim300_min100_win5\"\n",
    "we_vector_size = 300\n",
    "we_model_dir = '../data/external/wiki-english/wiki-english-20171001/%s' % we_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done!\n"
     ]
    }
   ],
   "source": [
    "we_model = Word2Vec.load(we_model_dir+'/model.gensim')\n",
    "\n",
    "print ('loading done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEPATH = '../data/interim/association_metric_exps.pickle'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following terms were removed from the list first_list because they were not found in the we_model: ['bobbie-sue', 'sue-ellen']\n",
      "The following terms were removed from the list second_list because they were not found in the we_model: ['terryl', 'aiesha', 'lashelle', 'temeka', 'tameisha', 'teretha', 'laronya', 'shanise', 'lakisha', 'sharise', 'tashika', 'lashandra', 'shavonn']\n",
      "The following terms were removed from the first list to balance the length of the lists: ['roger', 'alan', 'frank', 'ian', 'justin', 'ryan', 'andrew', 'fred', 'jack', 'matthew', 'stephen']\n",
      "The following terms were removed from the list first_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list second_list because they were not found in the we_model: []\n"
     ]
    }
   ],
   "source": [
    "# WEAT 3\n",
    "EXP_NUM = 3\n",
    "X_terms = ['roger','alan','frank','ian','justin',\n",
    "          'ryan','andrew','fred','jack','matthew','stephen','brad','greg','jed',\n",
    "          'paul','todd','brandon','hank','jonathan','peter','wilbur','amanda',\n",
    "          'courtney','heather','melanie','sara','amber','crystal','katie',\n",
    "          'meredith','shannon','betsy','donna','kristin','nancy','stephanie',\n",
    "          'bobbie-sue','ellen','lauren','peggy','sue-ellen','colleen','emily',\n",
    "          'megan','rachel','wendy']\n",
    "Y_terms = ['alonzo','jamel','lerone','theo','alphonse','jerome','leroy',\n",
    "           'torrance','darnell','lamar','lionel','rashaun','tyree','deion',\n",
    "          'lamont','malik','terrence','tyrone','lavon','terryl',\n",
    "          'wardell','aiesha','lashelle','nichelle','shereen','temeka','ebony',\n",
    "          'latisha','shaniqua','tameisha','teretha','jasmine','laronya','shanise',\n",
    "          'tanisha','tia','lakisha','latoya','sharise','tashika','yolanda',\n",
    "          'lashandra','malika','shavonn','tawanda','yvette']\n",
    "A_terms = ['caress','freedom','health','love','peace','cheer','friend','heaven',\n",
    "          'loyal','pleasure','diamond','gentle','honest','lucky','rainbow',\n",
    "          'diploma','gift','honor','miracle','sunrise','family','happy','laughter',\n",
    "          'paradise','vacation']\n",
    "B_terms = ['abuse','crash','filth','murder','sickness','accident','death','grief',\n",
    "          'poison','stink','assault','disaster','hatred','pollute','tragedy','bomb',\n",
    "          'divorce','jail','poverty','ugly','cancer','evil','kill','rotten','vomit']\n",
    "X_terms, Y_terms = filter_terms_not_in_wemodel(we_model, X_terms, Y_terms)\n",
    "A_terms, B_terms = filter_terms_not_in_wemodel(we_model, A_terms, B_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First-Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [3][first_order_X]\n"
     ]
    }
   ],
   "source": [
    "metrics = get_1storder_association_metric_list_for_target_list(X_terms, A_terms, B_terms, we_model)\n",
    "# Make sure the last argument passed to save_array matches the first argument passed to\n",
    "# get_1storder_association_metric_list_for_target_list\n",
    "save_array(FILEPATH, metrics, EXP_NUM, 'first', 'X')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second-Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting association metric for all words: 100%|██████████████████████████████| 312425/312425 [03:20<00:00, 1560.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [3][second_order_X]\n"
     ]
    }
   ],
   "source": [
    "metrics = get_2ndorder_association_metric_list_for_target_list(X_terms, A_terms, B_terms, we_model)\n",
    "# Make sure the last argument passed to save_array matches the first argument passed to\n",
    "# get_1storder_association_metric_list_for_target_list\n",
    "save_array(FILEPATH, metrics, EXP_NUM, 'second', 'X')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving Results for Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {3: {'first_order_X': array([0.10917358, 0.11447405, 0.03977664, 0.21711674, 0.02069784,\n",
       "                     0.1428209 , 0.23171016, 0.10893403, 0.22164942, 0.1731362 ,\n",
       "                     0.03183159, 0.08439055, 0.13934323, 0.11403528, 0.10248176,\n",
       "                     0.15985223, 0.36892206, 0.13024949, 0.11066183, 0.19458479,\n",
       "                     0.17395213, 0.18826508, 0.09246605, 0.14566013, 0.14104251,\n",
       "                     0.12317574, 0.17753855, 0.17748386, 0.11440848, 0.06771086,\n",
       "                     0.07495613, 0.06568201, 0.12313557]),\n",
       "              'second_order_X': array([0.23449796, 0.2345688 , 0.0989702 , 0.37882134, 0.02910594,\n",
       "                     0.27740997, 0.16379115, 0.19063637, 0.41707927, 0.29391664,\n",
       "                     0.1971741 , 0.21215774, 0.3162869 , 0.2859519 , 0.3024328 ,\n",
       "                     0.18131642, 0.4094162 , 0.2760841 , 0.23804706, 0.30866247,\n",
       "                     0.30504382, 0.30536607, 0.20394868, 0.3266883 , 0.28670394,\n",
       "                     0.314532  , 0.30773422, 0.38299367, 0.3626843 , 0.20989752,\n",
       "                     0.20443484, 0.2916711 , 0.32588214], dtype=float32)}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_dict = open_pickle(FILEPATH)\n",
    "in_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23449796, 0.2345688 , 0.0989702 , 0.37882134, 0.02910594,\n",
       "       0.27740997, 0.16379115, 0.19063637, 0.41707927, 0.29391664,\n",
       "       0.1971741 , 0.21215774, 0.3162869 , 0.2859519 , 0.3024328 ,\n",
       "       0.18131642, 0.4094162 , 0.2760841 , 0.23804706, 0.30866247,\n",
       "       0.30504382, 0.30536607, 0.20394868, 0.3266883 , 0.28670394,\n",
       "       0.314532  , 0.30773422, 0.38299367, 0.3626843 , 0.20989752,\n",
       "       0.20443484, 0.2916711 , 0.32588214], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXP_NUM = 3\n",
    "EXP_NAME = 'second_order_X'\n",
    "arr_for_plotting = in_dict[EXP_NUM][EXP_NAME]\n",
    "arr_for_plotting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
