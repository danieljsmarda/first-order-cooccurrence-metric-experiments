{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from models import filter_terms_not_in_wemodel, \\\n",
    "    get_2ndorder_association_metric_list_for_target_list, \\\n",
    "    get_1storder_association_metric_list_for_target_list, \\\n",
    "    get_expSG_1storder_relation_no_cache_NEW, \\\n",
    "    get_expSG_1storder_relation_no_cache_NEW_ALLWORDS, \\\n",
    "    get_matrices_from_term_lists, \\\n",
    "    save_arrays, open_pickle, save_pickle, \\\n",
    "    save_scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done!\n",
      "Total words: 2196016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\Miniconda3\\envs\\semproject2\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "we_model = KeyedVectors.load('../data/interim/glove_840_normed', mmap='r')\n",
    "print('loading done!')\n",
    "print(f'Total words: {len(we_model.wv.vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done!\n",
      "Total words: 312425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# Caliskan GloVe\\nglove_file = '../data/external/glove.6B/glove.6B.50d.txt'\\n_ = glove2word2vec(glove_file, '../data/interim/tmp.txt')\\nwe_model = KeyedVectors.load_word2vec_format('../data/interim/tmp.txt')\\nprint('loading done!')\\nprint(f'Total words: {len(we_model.wv.vocab)}')\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''we_model_name = \"sg_dim300_min100_win5\"\n",
    "we_vector_size = 300\n",
    "we_model_dir = '../data/external/wiki-english/wiki-english-20171001/%s' % we_model_name\n",
    "\n",
    "we_model = Word2Vec.load(we_model_dir+'/model.gensim')\n",
    "print ('loading done!')\n",
    "print(f'Total words: {len(we_model.wv.vocab)}')\n",
    "'''\n",
    "'''\n",
    "# Caliskan GloVe\n",
    "glove_file = '../data/external/glove.6B/glove.6B.50d.txt'\n",
    "_ = glove2word2vec(glove_file, '../data/interim/tmp.txt')\n",
    "we_model = KeyedVectors.load_word2vec_format('../data/interim/tmp.txt')\n",
    "print('loading done!')\n",
    "print(f'Total words: {len(we_model.wv.vocab)}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEPATH = '../data/interim/association_metric_exps.pickle'\n",
    "EXPERIMENT_DEFINITION_PATH = '../data/interim/experiment_definitions.pickle'\n",
    "THRESHOLD_BIASES_PATH_2NDORDER = '../data/processed/threshold_biases_2ndorder.pickle'\n",
    "THRESHOLD_BIASES_PATH_1STORDER = '../data/processed/threshold_biases_1storder.pickle'\n",
    "SCALERS_FILEPATH = '../data/processed/scalers.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_experiment_definition(exp_num, X_terms, Y_terms, A_terms, B_terms, X_label, Y_label, A_label, B_label, filepath):\n",
    "    dct = open_pickle(filepath)\n",
    "    dct[exp_num]['X_terms'] = X_terms\n",
    "    dct[exp_num]['Y_terms'] = Y_terms\n",
    "    dct[exp_num]['A_terms'] = A_terms\n",
    "    dct[exp_num]['B_terms'] = B_terms\n",
    "    dct[exp_num]['X_label'] = X_label\n",
    "    dct[exp_num]['Y_label'] = Y_label\n",
    "    dct[exp_num]['A_label'] = A_label\n",
    "    dct[exp_num]['B_label'] = B_label\n",
    "    save_pickle(dct, filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following terms were removed from the list first_list because they were not found in the we_model: ['gladiola']\n",
      "The following terms were removed from the list second_list because they were not found in the we_model: []\n",
      "The following terms were removed from the second list to balance the length of the lists: ['ant']\n",
      "The following terms were removed from the list first_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list second_list because they were not found in the we_model: []\n"
     ]
    }
   ],
   "source": [
    "# WEAT 1\n",
    "exp_num = 1\n",
    "X_label = 'Flowers'\n",
    "Y_label = 'Insects'\n",
    "A_label = 'Pleasant'\n",
    "B_label = 'Unpleasant'\n",
    "X_terms = ['aster', 'clover', 'hyacinth', 'marigold', 'poppy', 'azalea', \n",
    "           'crocus', 'iris', 'orchid', 'rose', 'bluebell', 'daffodil','lilac',\n",
    "           'pansy','tulip','buttercup','daisy','lily','penny','violet','carnation', 'gladiola',\n",
    "           'magnolia','petunia','zinnia']\n",
    "Y_terms = ['ant','caterpillar','flea','locust','spider','bedbug','centipede','fly',\n",
    "          'maggot','tarantula','bee','cockroach','gnat','mosquito','termite','beetle',\n",
    "          'cricket','hornet','moth','wasp','blackfly','dragonfly','horsefly','roach',\n",
    "          'weevil']\n",
    "A_terms = ['caress','freedom','health','love','peace','cheer','friend','heaven',\n",
    "           'loyal','pleasure','diamond','gentle','honest','lucky','rainbow','diploma',\n",
    "           'gift','honor','miracle','sunrise','family','happy','laugher','paradise',\n",
    "           'vacation']\n",
    "B_terms = ['abuse','crash','filth','murder','sickness','accident','death','grief',\n",
    "          'poison','stink','assault','disaster','hatred','pollute','tragedy',\n",
    "          'divorce','jail','poverty','ugly','cancer','kill','rotten','vomit','agony',\n",
    "          'prison']\n",
    "X_terms, Y_terms = filter_terms_not_in_wemodel(we_model, X_terms, Y_terms)\n",
    "A_terms, B_terms = filter_terms_not_in_wemodel(we_model, A_terms, B_terms)\n",
    "add_experiment_definition(exp_num, X_terms, Y_terms, A_terms, B_terms, \n",
    "                          X_label, Y_label, A_label, B_label, EXPERIMENT_DEFINITION_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following terms were removed from the list first_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list second_list because they were not found in the we_model: []\n",
      "The following terms were removed from the second list to balance the length of the lists: ['arrow']\n",
      "The following terms were removed from the list first_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list second_list because they were not found in the we_model: []\n"
     ]
    }
   ],
   "source": [
    "# WEAT 2\n",
    "exp_num = 2\n",
    "X_label = 'Instruments'\n",
    "Y_label = 'Weapons'\n",
    "A_label = 'Pleasant'\n",
    "B_label = 'Unpleasant'\n",
    "X_terms = ['bagpipe','cello','guitar','lute','trombone','banjo','clarinet','harmonica',\n",
    "           'mandolin','trumpet','bassoon','drum','harp','oboe','tuba','bell','fiddle',\n",
    "           'harpsichord','piano','viola','bongo','flute','horn','saxophone']\n",
    "Y_terms = ['arrow','club','gun','missile','spear','axe','dagger','harpoon','pistol',\n",
    "          'sword','blade','dynamite','hatchet','rifle','tank','bomb','firearm',\n",
    "          'knife','shotgun','teargas','cannon','grenade','mace','slingshot','whip']\n",
    "A_terms = ['caress','freedom','health','love','peace','cheer','friend','heaven',\n",
    "           'loyal','pleasure','diamond','gentle','honest','lucky','rainbow','diploma',\n",
    "           'gift','honor','miracle','sunrise','family','happy','laugher','paradise',\n",
    "           'vacation']\n",
    "B_terms = ['abuse','crash','filth','murder','sickness','accident','death','grief',\n",
    "          'poison','stink','assault','disaster','hatred','pollute','tragedy',\n",
    "          'divorce','jail','poverty','ugly','cancer','kill','rotten','vomit','agony',\n",
    "          'prison']\n",
    "X_terms, Y_terms = filter_terms_not_in_wemodel(we_model, X_terms, Y_terms)\n",
    "A_terms, B_terms = filter_terms_not_in_wemodel(we_model, A_terms, B_terms)\n",
    "add_experiment_definition(exp_num, X_terms, Y_terms, A_terms, B_terms, \n",
    "                          X_label, Y_label, A_label, B_label, EXPERIMENT_DEFINITION_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second-Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower bound: -0.12051583379507065\n",
      "Upper bound: 0.10539177060127258\n",
      "Lower bound: -0.12051583379507065\n",
      "Upper bound: 0.10539177060127258\n",
      "[ 0.06463376  0.13652503 -0.04676503  0.11253601  0.04916599  0.17652243\n",
      "  0.09883526  0.04855525  0.07594025  0.16368937  0.08388424  0.11431959\n",
      "  0.13489187  0.08018041  0.1137642   0.09362984  0.10222384  0.09800541\n",
      "  0.14387575  0.04530728  0.09423137  0.14132568  0.06971878  0.06853676]\n",
      "[-0.02787289 -0.01819867 -0.06967109 -0.01150721 -0.1667692  -0.06400925\n",
      "  0.04445949 -0.18263587 -0.07073748  0.11490756 -0.09649387 -0.04441088\n",
      " -0.11249268 -0.08999455 -0.10317296  0.02992854  0.0309861  -0.02143282\n",
      " -0.06515384  0.02837816  0.04654327  0.03567371  0.03692234 -0.11014193]\n",
      "mean bias to X 0.09431389\n",
      "mean bias to Y -0.036954004\n",
      "Bias threshold 0.0380725\n",
      "5th percentile 0.006891302671283487\n",
      "95th percentile 0.557002368569374\n",
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [1][second]\n"
     ]
    }
   ],
   "source": [
    "def calculate_cosines_for_target_word_unscaled(word_vec, A_mtx, B_mtx):\n",
    "    A_dot_v = np.dot(A_mtx, word_vec)\n",
    "    B_dot_v = np.dot(B_mtx, word_vec)\n",
    "    A_norms = np.multiply(np.linalg.norm(A_mtx, axis=1), np.linalg.norm(word_vec))\n",
    "    B_norms = np.multiply(np.linalg.norm(B_mtx, axis=1), np.linalg.norm(word_vec))\n",
    "    A_cosines = np.divide(A_dot_v, A_norms)\n",
    "    B_cosines = np.divide(B_dot_v, B_norms)\n",
    "    return np.mean(A_cosines), np.mean(B_cosines)\n",
    "\n",
    "def calculate_cosines_for_all_words_unscaled(we_model, A_mtx, B_mtx):\n",
    "    '''Computes the association metric, s(w,A,B).\n",
    "    word_vec: 1-D word vector\n",
    "    A_mtx, B_mtx: 2-D word vector arrays'''\n",
    "    #A_cosines_apply = np.apply_along_axis(lambda row: 1-cosine_distance(row, word_vec), 1, A_mtx)\n",
    "    #B_cosines_apply = np.apply_along_axis(lambda row: 1-cosine_distance(row, word_vec), 1, B_mtx)\n",
    "    A_mtx_norm = A_mtx/np.linalg.norm(A_mtx, axis=1).reshape(-1,1)\n",
    "    B_mtx_norm = B_mtx/np.linalg.norm(B_mtx, axis=1).reshape(-1,1)\n",
    "    all_mtx_norm = we_model.wv.vectors/np.linalg.norm(we_model.wv.vectors, axis=1).reshape(-1,1)\n",
    "    \n",
    "    all_associations_to_A = np.dot(A_mtx_norm, all_mtx_norm.T)\n",
    "    all_associations_to_B = np.dot(B_mtx_norm, all_mtx_norm.T)\n",
    "    \n",
    "    return np.mean(all_associations_to_A, axis=0), np.mean(all_associations_to_B, axis=0)\n",
    "\n",
    "\n",
    "def get_2ndorder_association_metric_list_for_target_list(target_list, A_terms, B_terms, we_model, exp_num):\n",
    "    \n",
    "    [X_mtx, _, A_mtx, B_mtx] = get_matrices_from_term_lists(we_model, target_list, target_list, A_terms, B_terms)\n",
    "    \n",
    "    # A_associations, B_associations are associations for all words    \n",
    "    A_associations, B_associations = calculate_cosines_for_all_words_unscaled(we_model, A_mtx, B_mtx)\n",
    "    \n",
    "    \n",
    "    all_associations = np.concatenate((A_associations, B_associations))\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    scaler.fit(all_associations.reshape(-1,1))\n",
    "    save_scalers(SCALERS_FILEPATH, exp_num, 'second', scaler)\n",
    "    \n",
    "    _th = np.mean(np.abs(A_associations - B_associations))\n",
    "    _th = scaler.transform(_th.reshape(-1, 1))[0,0]\n",
    "               \n",
    "    threshold_biases = open_pickle(THRESHOLD_BIASES_PATH_2NDORDER)\n",
    "    threshold_biases = scaler.transform(threshold_biases.reshape(-1,1))\n",
    "    pct_5 = np.percentile(threshold_biases, 5)\n",
    "    pct_95 = np.percentile(threshold_biases, 95)\n",
    "    \n",
    "    biases = A_associations - B_associations\n",
    "    biases = scaler.transform(biases.reshape(-1, 1))\n",
    "    lower_bound = np.percentile(biases, 5)\n",
    "    print(f'Lower bound: {lower_bound}')\n",
    "    upper_bound = np.percentile(biases, 95)\n",
    "    print(f'Upper bound: {upper_bound}')\n",
    "    \n",
    "    target_associations = np.apply_along_axis(lambda x_vec: calculate_cosines_for_target_word_unscaled(x_vec, A_mtx, B_mtx), 1, X_mtx)\n",
    "    \n",
    "    target_biases = []\n",
    "    A_biases = []\n",
    "    for _assoc in target_associations:\n",
    "        _A_assoc = scaler.transform(_assoc[0].reshape(-1, 1))[0,0]\n",
    "        _B_assoc = scaler.transform(_assoc[1].reshape(-1, 1))[0,0]\n",
    "        _bias = _A_assoc - _B_assoc\n",
    "        target_biases.append(_bias)\n",
    "        A_biases.append(_A_assoc)\n",
    "    return np.array(target_biases), _th, pct_5, pct_95, np.array(A_biases), lower_bound, upper_bound\n",
    "\n",
    "def run_exps_2ndorder(X_terms, Y_terms, A_terms, B_terms, exp_num):\n",
    "    order='second'\n",
    "    X_metrics, _th, pct_5, pct_95, A_biases, lower_bound, upper_bound = get_2ndorder_association_metric_list_for_target_list(X_terms, A_terms, B_terms, we_model, exp_num)\n",
    "    Y_metrics, _th, pct_5, pct_95, A_biases, lower_bound, upper_bound = get_2ndorder_association_metric_list_for_target_list(Y_terms, A_terms, B_terms, we_model, exp_num)\n",
    "    print (X_metrics)\n",
    "    print (Y_metrics)\n",
    "\n",
    "    print ('mean bias to X', np.mean(X_metrics))\n",
    "    print ('mean bias to Y', np.mean(Y_metrics))\n",
    "\n",
    "    print ('Bias threshold', _th)\n",
    "    print ('5th percentile', pct_5)\n",
    "    print ('95th percentile', pct_95)\n",
    "\n",
    "    order = 'second'\n",
    "    threshold = _th\n",
    "    save_arrays(FILEPATH, exp_num, order, X_metrics, Y_metrics, threshold, pct_5, pct_95, A_biases, lower_bound, upper_bound)\n",
    "run_exps_2ndorder(X_terms, Y_terms, A_terms, B_terms, exp_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORDER = second\n",
      "***********************************\n",
      "Experiment: 1\n",
      "Lower bound: -0.12051583379507065\n",
      "Upper bound: 0.10539177060127258\n",
      "Lower bound: -0.12051583379507065\n",
      "Upper bound: 0.10539177060127258\n",
      "[ 0.06463376  0.13652503 -0.04676503  0.11253601  0.04916599  0.17652243\n",
      "  0.09883526  0.04855525  0.07594025  0.16368937  0.08388424  0.11431959\n",
      "  0.13489187  0.08018041  0.1137642   0.09362984  0.10222384  0.09800541\n",
      "  0.14387575  0.04530728  0.09423137  0.14132568  0.06971878  0.06853676]\n",
      "[-0.02787289 -0.01819867 -0.06967109 -0.01150721 -0.1667692  -0.06400925\n",
      "  0.04445949 -0.18263587 -0.07073748  0.11490756 -0.09649387 -0.04441088\n",
      " -0.11249268 -0.08999455 -0.10317296  0.02992854  0.0309861  -0.02143282\n",
      " -0.06515384  0.02837816  0.04654327  0.03567371  0.03692234 -0.11014193]\n",
      "mean bias to X 0.09431389\n",
      "mean bias to Y -0.036954004\n",
      "Bias threshold 0.0380725\n",
      "5th percentile 0.006891302671283487\n",
      "95th percentile 0.557002368569374\n",
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [1][second]\n",
      "***********************************\n",
      "Experiment: 2\n",
      "Lower bound: -0.12051583379507065\n",
      "Upper bound: 0.10539177060127258\n",
      "Lower bound: -0.12051583379507065\n",
      "Upper bound: 0.10539177060127258\n",
      "[0.06205934 0.09165296 0.0919002  0.11380053 0.09113181 0.11897811\n",
      " 0.10779971 0.08894435 0.11067972 0.14237365 0.09621373 0.1135487\n",
      " 0.14185229 0.06471875 0.08086327 0.15060195 0.12328166 0.13162217\n",
      " 0.18247157 0.08507252 0.04209799 0.12344435 0.08338574 0.09611011]\n",
      "[ 0.20805708 -0.08329672 -0.09894511  0.01462591 -0.12913164 -0.04405615\n",
      " -0.02649808 -0.0268372   0.05020308 -0.01089379 -0.04618579 -0.09935915\n",
      " -0.03268984 -0.01189023 -0.25332013 -0.15611374 -0.1442793  -0.12644878\n",
      " -0.21717617  0.0141916  -0.12324518  0.01065516  0.03379461  0.03538892]\n",
      "mean bias to X 0.105608545\n",
      "mean bias to Y -0.052643776\n",
      "Bias threshold 0.0380725\n",
      "5th percentile 0.006891302671283487\n",
      "95th percentile 0.557002368569374\n",
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [2][second]\n",
      "***********************************\n",
      "Experiment: 3\n",
      "Lower bound: -0.11998455822467803\n",
      "Upper bound: 0.10168652534484854\n",
      "Lower bound: -0.11998455822467803\n",
      "Upper bound: 0.10168652534484854\n",
      "[ 0.05274689  0.05277491 -0.00089893  0.10987422 -0.02855325  0.0697327\n",
      "  0.02475902  0.03538519  0.12501785  0.07626653  0.03797302  0.04390398\n",
      "  0.0851213   0.07311377  0.07963744  0.03169608  0.12198457  0.06920785\n",
      "  0.05415171  0.08210334  0.08067098  0.08079851  0.04065457  0.08923844\n",
      "  0.07341152  0.08442664  0.08173588  0.11152574  0.10348672  0.04300928\n",
      "  0.040847    0.07537764  0.08891937]\n",
      "[ 0.01200029 -0.04887313 -0.0189175   0.02980676  0.05098388  0.13200343\n",
      "  0.10986358  0.06962061  0.09562543  0.06726372  0.04168728 -0.01561373\n",
      "  0.03160989 -0.04158163  0.05495003  0.01093769  0.05614945  0.00263932\n",
      "  0.01242352  0.05940512  0.01646861  0.02783528  0.06215191 -0.01567909\n",
      " -0.12108016  0.12908036 -0.03620315  0.01230663  0.03659087  0.06081846\n",
      "  0.08755919 -0.02113622  0.02869248]\n",
      "mean bias to X 0.06636668\n",
      "mean bias to Y 0.02967846\n",
      "Bias threshold 0.03192351\n",
      "5th percentile 0.0006124431267380753\n",
      "95th percentile 0.5430908203125\n",
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [3][second]\n",
      "***********************************\n",
      "Experiment: 4\n",
      "Lower bound: -0.12791535556316375\n",
      "Upper bound: 0.10053487122058867\n",
      "Lower bound: -0.12791535556316375\n",
      "Upper bound: 0.10053487122058867\n",
      "[ 0.0416376   0.04204524  0.0521923   0.04656783  0.09875625  0.06051609\n",
      "  0.07799956 -0.03084898  0.02298915  0.07719892 -0.02215308  0.05093539\n",
      "  0.04796621  0.0984351   0.04427794  0.05714163  0.06518334]\n",
      "[ 0.08914679  0.00348976  0.10374305  0.06023648  0.00116938  0.10917303\n",
      "  0.03866205 -0.04638812  0.0006488  -0.02213246  0.06024215  0.05969754\n",
      "  0.01021868  0.07925746  0.03632909  0.02086172 -0.04254031]\n",
      "mean bias to X 0.048872974\n",
      "mean bias to Y 0.033047944\n",
      "Bias threshold 0.03228686\n",
      "5th percentile 0.0006249791011214295\n",
      "95th percentile 0.5542071521282196\n",
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [4][second]\n",
      "***********************************\n",
      "Experiment: 5\n",
      "Lower bound: -0.04112800881266594\n",
      "Upper bound: 0.1492934584617614\n",
      "Lower bound: -0.04112800881266594\n",
      "Upper bound: 0.1492934584617614\n",
      "[ 0.03448185 -0.00224099  0.03855988  0.02563772  0.10021123  0.0825074\n",
      "  0.04624766 -0.03126425  0.00982404  0.12099648  0.07860586  0.12772086\n",
      "  0.05174908  0.04297349  0.05040404  0.05489445  0.13147491]\n",
      "[ 0.07096952  0.05238089  0.05633342  0.06018037  0.03265777  0.05781707\n",
      "  0.05888727 -0.08586502  0.0380435   0.0673539   0.01311928  0.06538364\n",
      "  0.0151515   0.1285052   0.01343369  0.00568864  0.0506579 ]\n",
      "mean bias to X 0.056634337\n",
      "mean bias to Y 0.041217558\n",
      "Bias threshold 0.089500055\n",
      "5th percentile 0.05866230167448521\n",
      "95th percentile 0.41462519317865365\n",
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [5][second]\n",
      "***********************************\n",
      "Experiment: 6\n",
      "Lower bound: -0.09686482548713683\n",
      "Upper bound: 0.16727700531482695\n",
      "Lower bound: -0.09686482548713683\n",
      "Upper bound: 0.16727700531482695\n",
      "[-0.00437704 -0.00661263  0.1017907   0.03478983  0.07336998  0.06048223\n",
      "  0.07196188  0.04806051]\n",
      "[-0.13671872 -0.11727518 -0.08843803 -0.24054876 -0.19675577 -0.14031494\n",
      " -0.14450234 -0.09561354]\n",
      "mean bias to X 0.047433183\n",
      "mean bias to Y -0.1450209\n",
      "Bias threshold 0.10804567\n",
      "5th percentile 0.058474667184054856\n",
      "95th percentile 0.38120770752429955\n",
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [6][second]\n",
      "***********************************\n",
      "Experiment: 7\n",
      "Lower bound: -0.014801249653100966\n",
      "Upper bound: 0.13078886866569517\n",
      "Lower bound: -0.014801249653100966\n",
      "Upper bound: 0.13078886866569517\n",
      "[-0.00543517 -0.00100611  0.02044468  0.01612484  0.01350568  0.0014043\n",
      "  0.00838801 -0.00388923]\n",
      "[-0.06759894 -0.07480019 -0.10288882 -0.07515609 -0.08187169  0.003297\n",
      " -0.05195507 -0.03135499]\n",
      "mean bias to X 0.0061921254\n",
      "mean bias to Y -0.0602911\n",
      "Bias threshold 0.09672795\n",
      "5th percentile 0.07524772509932519\n",
      "95th percentile 0.3629843682050704\n",
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [7][second]\n",
      "***********************************\n",
      "Experiment: 8\n",
      "Lower bound: 0.0070087164640426644\n",
      "Upper bound: 0.13731459379196168\n",
      "Lower bound: 0.0070087164640426644\n",
      "Upper bound: 0.13731459379196168\n",
      "[ 0.01901111  0.03253692  0.03378958  0.00089476 -0.00041786  0.00306067\n",
      " -0.0280391   0.0188244 ]\n",
      "[-0.05945396 -0.03422916 -0.00536197 -0.0829007  -0.03337431 -0.08322144\n",
      "  0.00044104 -0.05116981]\n",
      "mean bias to X 0.009957559\n",
      "mean bias to Y -0.04365879\n",
      "Bias threshold 0.104926184\n",
      "5th percentile 0.08411358334124089\n",
      "95th percentile 0.3192106842994689\n",
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [8][second]\n",
      "***********************************\n",
      "Experiment: 9\n",
      "Lower bound: -0.07870265692472458\n",
      "Upper bound: 0.11291608512401577\n",
      "Lower bound: -0.07870265692472458\n",
      "Upper bound: 0.11291608512401577\n",
      "[ 0.03386626 -0.07979524  0.00746208 -0.02612928 -0.07694685 -0.12389636]\n",
      "[-0.14769801 -0.19796997 -0.26377875 -0.3501442  -0.21033448 -0.29953733]\n",
      "mean bias to X -0.044239897\n",
      "mean bias to Y -0.24491046\n",
      "Bias threshold 0.0846284\n",
      "5th percentile 0.056515208259224896\n",
      "95th percentile 0.5067405074834823\n",
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [9][second]\n",
      "***********************************\n",
      "Experiment: 10\n",
      "Lower bound: -0.04112800881266594\n",
      "Upper bound: 0.1492934584617614\n",
      "Lower bound: -0.04112800881266594\n",
      "Upper bound: 0.1492934584617614\n",
      "[0.08704966 0.13278893 0.07195443 0.08396614 0.03002673 0.08783937\n",
      " 0.06142583 0.03396758]\n",
      "[ 0.0856488   0.10658559  0.09809166  0.06114623  0.02103129 -0.01275337\n",
      "  0.05044705  0.0539431 ]\n",
      "mean bias to X 0.07362734\n",
      "mean bias to Y 0.058017544\n",
      "Bias threshold 0.089500055\n",
      "5th percentile 0.05866230167448521\n",
      "95th percentile 0.41462519317865365\n",
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [10][second]\n"
     ]
    }
   ],
   "source": [
    "def run_all_exps(order='second'):\n",
    "    exps = open_pickle(EXPERIMENT_DEFINITION_PATH)\n",
    "    print(f'ORDER = {order}')\n",
    "    for exp_num, exp in exps.items():\n",
    "        print('***********************************')\n",
    "        print(f'Experiment: {exp_num}')\n",
    "        X_terms = exp['X_terms']\n",
    "        Y_terms = exp['Y_terms']\n",
    "        A_terms = exp['A_terms']\n",
    "        B_terms = exp['B_terms']\n",
    "        if order == 'second':\n",
    "            run_exps_2ndorder(X_terms, Y_terms, A_terms, B_terms, exp_num)\n",
    "        else:\n",
    "            run_exps_1storder(X_terms, Y_terms, A_terms, B_terms, exp_num)\n",
    "run_all_exps(order='second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
