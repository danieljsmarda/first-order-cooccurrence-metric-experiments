{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import copy\n",
    "from statistics import mean\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim import utils\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.lsimodel import LsiModel\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from models import get_matrices_from_term_lists, produce_effect_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_model_name = \"sg_dim300_min100_win5\"\n",
    "we_vector_size = 300\n",
    "we_model_dir = '../data/external/wiki-english/wiki-english-20171001/%s' % we_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done!\n"
     ]
    }
   ],
   "source": [
    "we_model = Word2Vec.load(we_model_dir+'/model.gensim')\n",
    "\n",
    "print ('loading done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\Miniconda3\\envs\\semproject\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.12733914, -0.08342427,  0.16369039, -0.21538447,  0.14228454,\n",
       "        0.00829218,  0.18249302,  0.03723789, -0.07433749, -0.17181633,\n",
       "       -0.2403415 , -0.31628737,  0.00648428, -0.1407163 , -0.18559778,\n",
       "       -0.2550604 ,  0.04433366,  0.01166777, -0.10130986, -0.13285924,\n",
       "       -0.06508999, -0.00890678,  0.17122649,  0.30153406,  0.10102404,\n",
       "       -0.16058509, -0.01278191,  0.01183818, -0.0335123 , -0.15908985,\n",
       "       -0.01373081, -0.14647457,  0.15658577,  0.05838944, -0.15460949,\n",
       "        0.01621989,  0.02162932, -0.18378492,  0.32068068, -0.00999494,\n",
       "       -0.27018073,  0.2592168 , -0.0147164 , -0.10615241, -0.5176828 ,\n",
       "       -0.03581639, -0.00578303,  0.00869335,  0.47046474,  0.18723992,\n",
       "        0.20179759, -0.15939656, -0.19770053, -0.1105013 ,  0.04323676,\n",
       "        0.261503  ,  0.21725641,  0.11865173, -0.08013157,  0.11658183,\n",
       "        0.0284771 , -0.12727183,  0.28431818,  0.05774978, -0.03682013,\n",
       "       -0.1408243 , -0.09530429,  0.2631356 ,  0.0708516 ,  0.1251318 ,\n",
       "        0.04187702,  0.03543552, -0.10853253, -0.1839235 , -0.10448592,\n",
       "       -0.04929283,  0.25438532,  0.23987709, -0.24164297,  0.07727636,\n",
       "        0.280295  , -0.1435811 ,  0.1306506 ,  0.21138301,  0.03540181,\n",
       "       -0.19423848, -0.01826333, -0.0728633 ,  0.17127585, -0.18542975,\n",
       "       -0.2672573 , -0.12477041,  0.03840844, -0.11333783,  0.2924741 ,\n",
       "       -0.0637009 , -0.02670044,  0.09107408, -0.5016395 ,  0.21151263,\n",
       "        0.260003  ,  0.18822972, -0.51449054,  0.17447048,  0.15881261,\n",
       "       -0.28904784, -0.32309285,  0.30266398,  0.24552524, -0.00368373,\n",
       "        0.10565484,  0.10777181, -0.15145451,  0.03503991, -0.18703867,\n",
       "        0.14373021,  0.27706593, -0.18775406, -0.08055554,  0.19336766,\n",
       "       -0.26110628, -0.3856879 ,  0.43220398,  0.13158925,  0.03218917,\n",
       "       -0.00352631, -0.07850631, -0.07453234,  0.19587578,  0.11386965,\n",
       "       -0.02721252, -0.17590368,  0.12985119, -0.16034245,  0.4876512 ,\n",
       "       -0.2555224 ,  0.18424027, -0.36833462,  0.00624407, -0.2612001 ,\n",
       "       -0.07328119,  0.32703725,  0.17698316, -0.08080297, -0.24163993,\n",
       "       -0.08379387,  0.46368915, -0.1812373 ,  0.35271314, -0.23164064,\n",
       "       -0.02064711,  0.16205384, -0.04472222,  0.1656516 , -0.14718047,\n",
       "       -0.20080477, -0.28046846, -0.07197856,  0.08879314,  0.09023961,\n",
       "       -0.25619695, -0.13003083, -0.09271947, -0.27586666,  0.46215564,\n",
       "        0.16950871,  0.3150692 , -0.34521455,  0.18535975, -0.15115058,\n",
       "        0.00123248,  0.15815651, -0.01478151,  0.2313867 ,  0.18361555,\n",
       "       -0.14717768, -0.43083775,  0.25108236, -0.00302948, -0.0253676 ,\n",
       "       -0.41203824,  0.18428096, -0.12652399, -0.01305293, -0.14082152,\n",
       "       -0.0616459 ,  0.08722878, -0.00963022,  0.22965989, -0.02846964,\n",
       "       -0.27203086, -0.08119329,  0.10476013,  0.04496747, -0.18778653,\n",
       "       -0.28145686,  0.14267501,  0.47639263, -0.14322719, -0.02256796,\n",
       "       -0.2903892 ,  0.22751476, -0.13927612,  0.4134543 , -0.08061898,\n",
       "       -0.23368499,  0.3315714 , -0.35515356,  0.12184373,  0.07241866,\n",
       "       -0.26642388, -0.06114953, -0.06330679, -0.259485  , -0.08273522,\n",
       "        0.16052216, -0.22007613,  0.34168187,  0.16528943,  0.3561633 ,\n",
       "        0.00790104,  0.40442824, -0.12869325, -0.02252908,  0.07855526,\n",
       "        0.0966503 ,  0.13478303,  0.14832854, -0.11354709,  0.17730169,\n",
       "       -0.02816416,  0.11894435, -0.20671207, -0.03840825,  0.279556  ,\n",
       "        0.03780328,  0.13083483, -0.24928112,  0.29876953, -0.21982463,\n",
       "       -0.08034156, -0.07345845,  0.08712874, -0.2525526 ,  0.01569675,\n",
       "        0.0855477 , -0.00924237, -0.14990923, -0.10968917, -0.04844077,\n",
       "       -0.4240703 , -0.05878971,  0.18688433,  0.22059937, -0.28032348,\n",
       "        0.28669283,  0.29358825,  0.06142302,  0.12324408,  0.05010409,\n",
       "        0.12053856, -0.06188652,  0.320109  , -0.20744109,  0.03640291,\n",
       "        0.03683271,  0.40558824,  0.30551803,  0.29174578, -0.05158916,\n",
       "        0.21834846, -0.07879724, -0.05102563,  0.14190584,  0.10773157,\n",
       "        0.12599686,  0.0588461 ,  0.2801925 ,  0.0496694 , -0.13759921,\n",
       "        0.11787671,  0.07902818, -0.01346854, -0.4380222 ,  0.2678219 ,\n",
       "        0.14008404, -0.00983391, -0.19902468,  0.08660395,  0.1688792 ,\n",
       "       -0.01770646, -0.25552115, -0.20781791,  0.29046363,  0.28488013,\n",
       "        0.13732651, -0.04422138,  0.02443623,  0.05531725,  0.25724363],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "we_model['car']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading E_ctx_vec\n",
    "with open(we_model_dir+'/E_ctx_vec.pkl', 'rb') as fr:\n",
    "    E_ctx_vec = pickle.load(fr)\n",
    "with open(we_model_dir+'/E_wrd_vec.pkl', 'rb') as fr:\n",
    "    E_wrd_vec = pickle.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'book': array([0.24737692, 0.56118023, 0.68307143, ..., 0.09694416, 0.18521136,\n",
       "        0.15946515], dtype=float32)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_expSG_vecs(words):\n",
    "    \n",
    "    expSG_vecs = {}\n",
    "    for word in words:\n",
    "        _idx = we_model.wv.vocab[word].index\n",
    "        _vec = we_model.wv.vectors[_idx]\n",
    "        \n",
    "        # explicit SkipGram\n",
    "        expSG_vecs[word] = scipy.special.expit(np.dot(we_model.trainables.syn1neg, _vec))\n",
    "        expSG_vecs[word] /= np.sqrt(E_ctx_vec * E_wrd_vec[_idx])\n",
    "    \n",
    "    return expSG_vecs\n",
    "\n",
    "get_expSG_vecs(['book'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'book': 11.011071, 'library': 3.6249995}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_expSG_1storder_relation(word_from, words_to):\n",
    "    expSG_vec = get_expSG_vecs([word_from])[word_from]\n",
    "    \n",
    "    relations={}\n",
    "    for word_to in words_to:\n",
    "        if word_to in we_model.wv.vocab:\n",
    "            _idx = we_model.wv.vocab[word_to].index\n",
    "            relations[word_to] = expSG_vec[_idx]\n",
    "    \n",
    "    return relations\n",
    "\n",
    "get_expSG_1storder_relation('book', ['book', 'library'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expSG_1storder_relation_scaled(word_from, words_to):\n",
    "    expSG_vec = get_expSG_vecs([word_from])[word_from]\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(expSG_vec.reshape(-1, 1))\n",
    "\n",
    "    relations={}\n",
    "    for word_to in words_to:\n",
    "        if word_to in we_model.wv.vocab:\n",
    "            _idx = we_model.wv.vocab[word_to].index\n",
    "            _value = expSG_vec[_idx]\n",
    "            _value_scaled = scaler.transform(np.array([_value]).reshape(1, -1))[0][0]\n",
    "            relations[word_to] = _value_scaled\n",
    "    \n",
    "    return relations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating *d*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_terms = ['book','library']\n",
    "B_terms = ['car','garage']\n",
    "X_terms = ['female','woman']\n",
    "Y_terms = ['male','man']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.6768265"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This function is untested\n",
    "def get_1storder_association_metric(word, A_terms, B_terms):\n",
    "    A_relations = get_expSG_1storder_relation(word, A_terms)\n",
    "    B_relations = get_expSG_1storder_relation(word, B_terms)\n",
    "    return mean(A_relations.values()) - mean(B_relations.values())\n",
    "get_1storder_association_metric('book', ['book','library'], ['car','garage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'car': 0.3352654, 'garage': 0.9471519}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_expSG_1storder_relation('book',['car','garage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WEAT 6\n",
    "X_terms = ['John', 'Paul','Mike','Kevin','Steve','Greg','Jeff','Bill']\n",
    "Y_terms = ['Amy','Joan','Lisa','Sarah','Diana','Kate','Ann','Donna']\n",
    "A_terms = ['executive','management','professional','corporation',\n",
    "               'salary','office','business','career']\n",
    "B_terms = ['home','parents','children','family',\n",
    "               'cousins','marriage','wedding','relatives']\n",
    "[X_terms, Y_terms, A_tersm, B_terms] = [[str.lower(term) for term in terms] for terms in [X_terms, Y_terms, A_terms, B_terms]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WEAT 7 using Google News word2vec model\n",
    "X_terms = ['math','algebra','geometry','calculus',\n",
    "             'equations','computation','numbers','addition']\n",
    "Y_terms = ['poetry','art','dance','literature',\n",
    "             'novel','symphony','drama','sculpture']\n",
    "A_terms = ['male','man','boy','brother',\n",
    "              'he','him','his','son']\n",
    "B_terms = ['female','woman','girl','sister',\n",
    "               'she','her','hers','daughter']\n",
    "[X_terms, Y_terms, A_tersm, B_terms] = [[str.lower(term) for term in terms] for terms in [X_terms, Y_terms, A_terms, B_terms]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weat 8\n",
    "A_terms = ['brother','father','uncle','grandfather',\n",
    "          'son','he','his','him']\n",
    "B_terms = ['sister','mother','aunt','grandmother',\n",
    "          'daughter','she','hers','her']\n",
    "X_terms = ['science','technology','physics','chemistry',\n",
    "          'Einstein','NASA','experiment','astronomy']\n",
    "Y_terms = ['poetry','art','Shakespeare','dance',\n",
    "          'literature','novel','symphony','drama']\n",
    "[X_terms, Y_terms, A_tersm, B_terms] = [[str.lower(term) for term in terms] for terms in [X_terms, Y_terms, A_terms, B_terms]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4705007085670068"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def produce_1storder_effect_size_unnormalized(X_terms, Y_terms, A_terms, B_terms):\n",
    "    x_associations = np.array([])\n",
    "    y_associations = np.array([])\n",
    "    for (x,y) in zip(X_terms, Y_terms):\n",
    "        x_association = get_1storder_association_metric(x, A_terms, B_terms)\n",
    "        y_association = get_1storder_association_metric(y, A_terms, B_terms)\n",
    "        x_associations = np.append(x_associations, x_association)\n",
    "        y_associations = np.append(y_associations, y_association)\n",
    "    all_associations = np.append(x_associations, y_associations)\n",
    "    return (np.mean(x_associations) - np.mean(y_associations))/np.std(all_associations, ddof=1)\n",
    "produce_1storder_effect_size_unnormalized(X_terms, Y_terms, A_terms, B_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results: WEAT 6: 1.8156 (1.89) WEAT 7: 1.648, Weat 8: 1.471 (1.24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second-Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4183265688072304"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "produce_effect_size(we_model, X_terms, Y_terms, A_terms, B_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results: 1.774, 1.595, 1.4183"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_1storder_association_metric_scaled(word, A_terms, B_terms):\n",
    "    A_relations = get_expSG_1storder_relation_scaled(word, A_terms)\n",
    "    B_relations = get_expSG_1storder_relation_scaled(word, B_terms)\n",
    "    return mean(A_relations.values()) - mean(B_relations.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4517385120046582"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def produce_1storder_effect_size_scaled(X_terms, Y_terms, A_terms, B_terms):\n",
    "    x_associations = np.array([])\n",
    "    y_associations = np.array([])\n",
    "    for (x,y) in zip(X_terms, Y_terms):\n",
    "        x_association = get_1storder_association_metric_scaled(x, A_terms, B_terms)\n",
    "        y_association = get_1storder_association_metric_scaled(y, A_terms, B_terms)\n",
    "        x_associations = np.append(x_associations, x_association)\n",
    "        y_associations = np.append(y_associations, y_association)\n",
    "    all_associations = np.append(x_associations, y_associations)\n",
    "    return (np.mean(x_associations) - np.mean(y_associations))/np.std(all_associations, ddof=1)\n",
    "produce_1storder_effect_size_scaled(X_terms, Y_terms, A_terms, B_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2nd order, 1st order unscaled, 1st order scaled)\n",
    "(1.774, 1.816, 1.759)\n",
    "(1.595, 1.648, 1.335)\n",
    "(1.4183, 1.471, 1.451)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
