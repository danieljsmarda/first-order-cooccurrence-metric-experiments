{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from tqdm import tqdm\n",
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "import random\n",
    "random.seed(5)\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from models import get_matrices_from_term_lists, \\\n",
    "    filter_terms_not_in_wemodel, \\\n",
    "    save_pickle, open_pickle, \\\n",
    "    save_experiment_arbitrary_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done!\n",
      "Total words: 312425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# Caliskan GloVe\\nglove_file = '../data/external/glove.6B/glove.6B.50d.txt'\\n_ = glove2word2vec(glove_file, '../data/interim/tmp.txt')\\nwe_model = KeyedVectors.load_word2vec_format('../data/interim/tmp.txt')\\nprint('loading done!')\\nprint(f'Total words: {len(we_model.wv.vocab)}')\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCALERS_FILEPATH = '../data/processed/scalers.pickle'\n",
    "\n",
    "we_model_name = \"sg_dim300_min100_win5\"\n",
    "we_vector_size = 300\n",
    "we_model_dir = '../data/external/wiki-english/wiki-english-20171001/%s' % we_model_name\n",
    "\n",
    "we_model = Word2Vec.load(we_model_dir+'/model.gensim')\n",
    "print ('loading done!')\n",
    "print(f'Total words: {len(we_model.wv.vocab)}')\n",
    "\n",
    "'''\n",
    "# Caliskan GloVe\n",
    "glove_file = '../data/external/glove.6B/glove.6B.50d.txt'\n",
    "_ = glove2word2vec(glove_file, '../data/interim/tmp.txt')\n",
    "we_model = KeyedVectors.load_word2vec_format('../data/interim/tmp.txt')\n",
    "print('loading done!')\n",
    "print(f'Total words: {len(we_model.wv.vocab)}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following terms were removed from the list first_list because they were not found in the we_model: ['gladiola']\n",
      "The following terms were removed from the list second_list because they were not found in the we_model: []\n",
      "The following terms were removed from the second list to balance the length of the lists: ['ant']\n",
      "The following terms were removed from the list first_list because they were not found in the we_model: []\n",
      "The following terms were removed from the list second_list because they were not found in the we_model: []\n"
     ]
    }
   ],
   "source": [
    "X_terms = ['aster', 'clover', 'hyacinth', 'marigold', 'poppy', 'azalea', \n",
    "           'crocus', 'iris', 'orchid', 'rose', 'bluebell', 'daffodil','lilac',\n",
    "           'pansy','tulip','buttercup','daisy','lily','penny','violet','carnation', 'gladiola',\n",
    "           'magnolia','petunia','zinnia']\n",
    "Y_terms = ['ant','caterpillar','flea','locust','spider','bedbug','centipede','fly',\n",
    "          'maggot','tarantula','bee','cockroach','gnat','mosquito','termite','beetle',\n",
    "          'cricket','hornet','moth','wasp','blackfly','dragonfly','horsefly','roach',\n",
    "          'weevil']\n",
    "A_terms = ['caress','freedom','health','love','peace','cheer','friend','heaven',\n",
    "           'loyal','pleasure','diamond','gentle','honest','lucky','rainbow','diploma',\n",
    "           'gift','honor','miracle','sunrise','family','happy','laugher','paradise',\n",
    "           'vacation']\n",
    "B_terms = ['abuse','crash','filth','murder','sickness','accident','death','grief',\n",
    "          'poison','stink','assault','disaster','hatred','pollute','tragedy',\n",
    "          'divorce','jail','poverty','ugly','cancer','kill','rotten','vomit','agony',\n",
    "          'prison']\n",
    "X_terms, Y_terms = filter_terms_not_in_wemodel(we_model, X_terms, Y_terms)\n",
    "A_terms, B_terms = filter_terms_not_in_wemodel(we_model, A_terms, B_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fastest version, 10000 words -> 1 minute\n",
    "# (Possible TODO) May be able to add minimal speedup with itemgetter \n",
    "# (see https://stackoverflow.com/questions/18453566/python-dictionary-get-list-of-values-for-list-of-keys)\n",
    "# to speed up creation of word matrices in get_matrices_from_term_lists\n",
    "def get_test_stat(wv_obj, X_terms, Y_terms, A_terms, B_terms):  \n",
    "    [X_mtx, Y_mtx, A_mtx, B_mtx] = get_matrices_from_term_lists(we_model, X_terms, Y_terms, A_terms, B_terms)\n",
    "    cosine_sim_XA = cosine_similarity(X_mtx, A_mtx)\n",
    "    cosine_sim_XB = cosine_similarity(X_mtx, B_mtx)\n",
    "    mean_over_Xa = np.mean(cosine_sim_XA, axis=1)\n",
    "    mean_over_Xb = np.mean(cosine_sim_XB, axis=1)\n",
    "    s_for_X_words = mean_over_Xa - mean_over_Xb\n",
    "    # shape is (24,) or (|X_terms|,)\n",
    "\n",
    "    cosine_sim_YA = cosine_similarity(Y_mtx, A_mtx)\n",
    "    cosine_sim_YB = cosine_similarity(Y_mtx, B_mtx)\n",
    "    mean_over_Ya = np.mean(cosine_sim_YA, axis=1)\n",
    "    mean_over_Yb = np.mean(cosine_sim_YB, axis=1)\n",
    "    s_for_Y_words = mean_over_Ya - mean_over_Yb\n",
    "    test_stat = np.mean(s_for_X_words) - np.mean(s_for_Y_words)\n",
    "    return test_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 10000/10000 [01:50<00:00, 90.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# This cell works too. It takes twice as long as the cell above,\n",
    "# but if we want to try to vectorize the outer loop, then \n",
    "# we will probably have to use this version\n",
    "def calculate_association_metric_for_target_word(word_vec, A_mtx, B_mtx):\n",
    "    '''Computes the association metric, s(w,A,B).\n",
    "    word_vec: 1-D word vector\n",
    "    A_mtx, B_mtx: 2-D word vector arrays'''\n",
    "    A_dot_v = np.dot(A_mtx, word_vec)\n",
    "    B_dot_v = np.dot(B_mtx, word_vec)\n",
    "    A_norms = np.multiply(np.linalg.norm(A_mtx, axis=1), np.linalg.norm(word_vec))\n",
    "    B_norms = np.multiply(np.linalg.norm(B_mtx, axis=1), np.linalg.norm(word_vec))\n",
    "    A_cosines = np.divide(A_dot_v, A_norms)\n",
    "    B_cosines = np.divide(B_dot_v, B_norms)\n",
    "    return np.mean(A_cosines) - np.mean(B_cosines)\n",
    "\n",
    "for i in tqdm(range(10000)):\n",
    "    [X_mtx, Y_mtx, A_mtx, B_mtx] = get_matrices_from_term_lists(we_model, X_terms, Y_terms, A_terms, B_terms)\n",
    "    X_associations = np.apply_along_axis(lambda x_vec: calculate_association_metric_for_target_word(x_vec, A_mtx, B_mtx), 1, X_mtx)\n",
    "    Y_associations = np.apply_along_axis(lambda y_vec: calculate_association_metric_for_target_word(y_vec, A_mtx, B_mtx), 1, Y_mtx)\n",
    "    m = np.mean(X_associations) - np.mean(Y_associations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_complements(x_union_y):\n",
    "    '''Generator function that yields pairs of equal-size disjoint subsets\n",
    "    of x_union_y.\n",
    "    x_union_y should a set type.'''\n",
    "    for seq in combinations(x_union_y, len(x_union_y)//2):\n",
    "        complement = frozenset(x_union_y.difference(seq))\n",
    "        yield (seq, complement)\n",
    "\n",
    "def produce_2ndorder_p_value(wv_obj, X_terms, Y_terms, A_terms, B_terms):\n",
    "    '''Generates the p-value for a set of terms with the word-vector object.\n",
    "    High-level function; this function should be directly imported into \n",
    "    notebooks for experimentation.'''\n",
    "    x_union_y = set(X_terms).union(set(Y_terms))\n",
    "    total_terms = len(x_union_y)\n",
    "    comparison_statistic = produce_test_statistic(wv_obj, X_terms, Y_terms, A_terms, B_terms)\n",
    "    dist = np.array([])\n",
    "    for (X_i_terms, Y_i_terms) in tqdm(get_complements(x_union_y), total=num_combinations(total_terms, total_terms/2)):\n",
    "        test_statistic = produce_test_statistic(wv_obj, X_i_terms, Y_i_terms, A_terms, B_terms)\n",
    "        dist = np.append(dist, test_statistic)\n",
    "    return 1 - sp.stats.norm.cdf(comparison_statistic, loc=np.mean(dist), scale=np.std(dist, ddof=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_test_stats(wv_obj, X_terms, Y_terms, A_terms, B_terms, n_samples=100):\n",
    "    sigtest_dist_1 = []\n",
    "    sigtest_dist_2 = []\n",
    "    sigtest_dist_3 = []\n",
    "    n_targets = len(X_terms)\n",
    "    n_attributes = len(A_terms)\n",
    "    assert len(X_terms) == len(Y_terms)\n",
    "    assert len(A_terms) == len(B_terms)\n",
    "    vocab_list = list(wv_obj.wv.vocab)\n",
    "    for i in tqdm(range(n_samples)):\n",
    "        X_sample = random.sample(vocab_list, k=n_targets)\n",
    "        Y_sample = random.sample(vocab_list, k=n_attributes)\n",
    "        sigtest_dist_1.append(get_test_stat(wv_obj, X_sample, Y_sample, A_terms, B_terms))\n",
    "        sigtest_dist_2.append(get_test_stat(wv_obj, X_terms, Y_sample, A_terms, B_terms))\n",
    "        sigtest_dist_3.append(get_test_stat(wv_obj, X_sample, Y_terms, A_terms, B_terms))\n",
    "    return np.array(sigtest_dist_1), np.array(sigtest_dist_2), np.array(sigtest_dist_3)\n",
    "#a,b,c = get_n_test_stats(we_model, X_terms, Y_terms, A_terms, B_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_experiment_arbitrary_label(filepath, exp_num, order, label, data, display=None):\n",
    "    results_dict = open_pickle(filepath)\n",
    "    results_dict[exp_num] = results_dict.get(exp_num, defaultdict(dict))\n",
    "    order_dict = results_dict[exp_num].get(order, {})\n",
    "    order_dict[label] = data\n",
    "    results_dict[exp_num][order] = order_dict\n",
    "    save_pickle(results_dict, filepath)\n",
    "    if display == 'all':\n",
    "        print(f'FULL RESULTS DICT FOR EXP {exp_num}', results_dict[exp_num])\n",
    "    elif display == 'some':\n",
    "        print(f'SPECIFIC RESULTS FOR EXP {exp_num}, LABEL \"{label}\": \\\n",
    "        {results_dict[exp_num][order][label]}')\n",
    "    print(f\"Results array successfully saved to file {filepath} under\\\n",
    " keys [{exp_num}][{order}][{label}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORDER = second\n",
      "******************************\n",
      "Experiment: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 77.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [1][second][sigtest_dist_1]\n",
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [1][second][sigtest_dist_2]\n",
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [1][second][sigtest_dist_3]\n",
      "******************************\n",
      "Experiment: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 70.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [2][second][sigtest_dist_1]\n",
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [2][second][sigtest_dist_2]\n",
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [2][second][sigtest_dist_3]\n",
      "******************************\n",
      "Experiment: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 62.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [3][second][sigtest_dist_1]\n",
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [3][second][sigtest_dist_2]\n",
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [3][second][sigtest_dist_3]\n",
      "******************************\n",
      "Experiment: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 71.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [4][second][sigtest_dist_1]\n",
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [4][second][sigtest_dist_2]\n",
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [4][second][sigtest_dist_3]\n",
      "******************************\n",
      "Experiment: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 92.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [5][second][sigtest_dist_1]\n",
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [5][second][sigtest_dist_2]\n",
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [5][second][sigtest_dist_3]\n",
      "******************************\n",
      "Experiment: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 111.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [6][second][sigtest_dist_1]\n",
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [6][second][sigtest_dist_2]\n",
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [6][second][sigtest_dist_3]\n",
      "******************************\n",
      "Experiment: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 99.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [7][second][sigtest_dist_1]\n",
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [7][second][sigtest_dist_2]\n",
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [7][second][sigtest_dist_3]\n",
      "******************************\n",
      "Experiment: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 115.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [8][second][sigtest_dist_1]\n",
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [8][second][sigtest_dist_2]\n",
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [8][second][sigtest_dist_3]\n",
      "******************************\n",
      "Experiment: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 118.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [9][second][sigtest_dist_1]\n",
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [9][second][sigtest_dist_2]\n",
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [9][second][sigtest_dist_3]\n",
      "******************************\n",
      "Experiment: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 103.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [10][second][sigtest_dist_1]\n",
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [10][second][sigtest_dist_2]\n",
      "Results array successfully saved to file ../data/interim/association_metric_exps.pickle under keys [10][second][sigtest_dist_3]\n"
     ]
    }
   ],
   "source": [
    "FILEPATH = '../data/interim/association_metric_exps.pickle'\n",
    "EXPERIMENT_DEFINITION_PATH = '../data/interim/experiment_definitions.pickle'\n",
    "def run_all_sigtests(order='second'):\n",
    "    exps = open_pickle(EXPERIMENT_DEFINITION_PATH)\n",
    "    scalers_dict = open_pickle(SCALERS_FILEPATH)\n",
    "    print(f'ORDER = {order}')\n",
    "    for exp_num, exp in exps.items():\n",
    "        print('******************************')\n",
    "        print(f'Experiment: {exp_num}')\n",
    "        X_terms = exp['X_terms']\n",
    "        Y_terms = exp['Y_terms']\n",
    "        A_terms = exp['A_terms']\n",
    "        B_terms = exp['B_terms']\n",
    "        if order == 'second':\n",
    "            scaler = scalers_dict[exp_num][order]\n",
    "            comparison_statistic = get_test_stat(we_model, X_terms, Y_terms, A_terms, B_terms)\n",
    "            dist_1, dist_2, dist_3 = get_n_test_stats(we_model, X_terms, Y_terms, A_terms, B_terms, n_samples=100)\n",
    "            [dist_1, dist_2, dist_3] = [scaler.transform(dist.reshape(-1,1)) for dist in [dist_1, dist_2, dist_3]]\n",
    "            save_experiment_arbitrary_label(FILEPATH, exp_num, order,\n",
    "                                            'sigtest_dist_1', dist_1)\n",
    "            save_experiment_arbitrary_label(FILEPATH, exp_num, order,\n",
    "                                            'sigtest_dist_2', dist_2)\n",
    "            save_experiment_arbitrary_label(FILEPATH, exp_num, order,\n",
    "                                            'sigtest_dist_3', dist_3)\n",
    "        else:\n",
    "            #TODO\n",
    "            raise NotImplementedError\n",
    "            run_exps_1storder(X_terms, Y_terms, A_terms, B_terms, exp_num)\n",
    "run_all_sigtests(order='second')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISTRIBUTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict, {'second': MinMaxScaler(copy=True, feature_range=(0, 1))})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open_pickle(SCALERS_FILEPATH)\n",
    "f[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
