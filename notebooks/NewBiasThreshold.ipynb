{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from gensim.models import Word2Vec\n",
    "from collections import defaultdict\n",
    "from scipy.spatial.distance import cosine as cosine_distance\n",
    "import random\n",
    "random.seed(5)\n",
    "import json\n",
    "import sys\n",
    "import random\n",
    "sys.path.append('../src')\n",
    "from models import word_set_to_mtx, save_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done!\n",
      "Total words: 312425\n"
     ]
    }
   ],
   "source": [
    "we_model_name = \"sg_dim300_min100_win5\"\n",
    "we_vector_size = 300\n",
    "we_model_dir = '../data/external/wiki-english/wiki-english-20171001/%s' % we_model_name\n",
    "\n",
    "we_model = Word2Vec.load(we_model_dir+'/model.gensim')\n",
    "print ('loading done!')\n",
    "print(f'Total words: {len(we_model.wv.vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD_BIASES_PATH_2NDORDER = '../data/processed/threshold_biases_2ndorder.pickle'\n",
    "THRESHOLD_BIASES_PATH_1STORDER = '../data/processed/threshold_biases_1storder.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wftv', 'stollwerck', 'dansville']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = list(we_model.wv.vocab.keys())\n",
    "random.choices(vocabulary, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_1 = random.choices(vocabulary, k=3)\n",
    "set_2 = random.choices(vocabulary, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1] [1 1 1]\n",
      "[ 2  5 10] [5 5 5]\n",
      "[ 3  5 10] [10 10 10]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_1 = np.array([[1, 1, 1], [2,5,10], [3,5,10]])\n",
    "set_2 = np.array([[1, 1, 1], [5, 5, 5], [10,10,10]])\n",
    "zip(set_1, set_2)\n",
    "[print(u,v) for u,v in zip(set_1, set_2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.86415857, 0.8977584 ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def matrix_cosine(x, y):\n",
    "    return np.einsum('ij,ij->i', x, y) / (\n",
    "              np.linalg.norm(x, axis=1) * np.linalg.norm(y, axis=1)\n",
    "    )\n",
    "print(type(set_1))\n",
    "matrix_cosine(set_1, set_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16863719, 0.12766281, 0.07611948, ..., 0.06586456, 0.19470786,\n",
       "       0.03731716], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_biases(we_model, k_pairs=10000, order='second'):\n",
    "    vocabulary = list(we_model.wv.vocab.keys())\n",
    "    set_1 = random.choices(vocabulary, k=k_pairs)\n",
    "    set_2 = random.choices(vocabulary, k=k_pairs)\n",
    "    arr_1 = word_set_to_mtx(we_model, set_1)\n",
    "    arr_2 = word_set_to_mtx(we_model, set_2)\n",
    "    if order == 'second':\n",
    "        biases = matrix_cosine(arr_1, arr_2)\n",
    "        save_pickle(biases, THRESHOLD_BIASES_PATH_2NDORDER)\n",
    "    else:\n",
    "        # Insert first-order function here, then remove \"break\" line\n",
    "        save_pickle(biases, THRESHOLD_BIASES_PATH_1STORDER)\n",
    "    return biases\n",
    "get_biases(we_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
